{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d566b5-f76b-405c-afd0-d8011554dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index graspologic numpy scipy future\n",
    "# !pip install --upgrade ipywidgets jupyter\n",
    "# %pip install llama-index-embeddings-azure-openai\n",
    "# %pip install llama-index-llms-azure-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff27fe10-b8d0-4d23-b715-8ee4b2638987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re, sys\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Load sample dataset\n",
    "news = pd.read_csv(\"news_articles.csv\")[100:150]\n",
    "\n",
    "# Convert data into LlamaIndex Document objects\n",
    "documents = [\n",
    "    Document(text=f\"{row['title']}: {row['text']}\")\n",
    "    for _, row in news.iterrows()\n",
    "]\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "entity_pattern = r'entity_name:\\s*(.+?)\\s*entity_type:\\s*(.+?)\\s*entity_description:\\s*(.+?)\\s*'\n",
    "relationship_pattern = r'source_entity:\\s*(.+?)\\s*target_entity:\\s*(.+?)\\s*relation:\\s*(.+?)\\s*relationship_description:\\s*(.+?)\\s*'\n",
    "\n",
    "def parse_fn(response_str: str):\n",
    "    entities = re.findall(entity_pattern, response_str)\n",
    "    relationships = re.findall(relationship_pattern, response_str)\n",
    "    return entities, relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dbe2e7-ed09-4f56-8a95-5eb9464059a4",
   "metadata": {},
   "source": [
    "# GraphRAGExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfe946c-8f78-4dd4-88be-02a5a1df2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import Any, List, Callable, Optional, Union, Dict\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    default_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY,\n",
    "    Relation,\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    \"\"\"Extract triples from a graph.\n",
    "\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM):\n",
    "            The language model to use.\n",
    "        extract_prompt (Union[str, PromptTemplate]):\n",
    "            The prompt to use for extracting triples.\n",
    "        parse_fn (callable):\n",
    "            A function to parse the output of the language model.\n",
    "        num_workers (int):\n",
    "            The number of workers to use for parallel processing.\n",
    "        max_paths_per_chunk (int):\n",
    "            The maximum number of paths to extract per chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes.\"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"Extract triples from a node.\"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            entities, entities_relationship = self.parse_fn(llm_response)\n",
    "        except ValueError:\n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
    "        metadata = node.metadata.copy()\n",
    "        for entity, entity_type, description in entities:\n",
    "            metadata[\n",
    "                \"entity_description\"\n",
    "            ] = description  # Not used in the current implementation. But will be useful in future work.\n",
    "            entity_node = EntityNode(\n",
    "                name=entity, label=entity_type, properties=metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "        metadata = node.metadata.copy()\n",
    "        for triple in entities_relationship:\n",
    "            subj, rel, obj, description = triple\n",
    "            subj_node = EntityNode(name=subj, properties=metadata)\n",
    "            obj_node = EntityNode(name=obj, properties=metadata)\n",
    "            metadata[\"relationship_description\"] = description\n",
    "            rel_node = Relation(\n",
    "                label=rel,\n",
    "                source_id=subj_node.id,\n",
    "                target_id=obj_node.id,\n",
    "                properties=metadata,\n",
    "            )\n",
    "\n",
    "            existing_nodes.extend([subj_node, obj_node])\n",
    "            existing_relations.append(rel_node)\n",
    "\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes async.\"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977aa56-8a70-40e3-b362-d4ed9c0e00a1",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8bae37-4286-4fd0-b444-fe873824383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_TRIPLET_EXTRACT_TMPL= \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
    "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: Type of the entity\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "Format each entity as (\"entity\")\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relation: relationship between source_entity and target_entity\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "\n",
    "Format each relationship as (\"relationship\")\n",
    "\n",
    "3. When finished, output.\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\"\n",
    "\n",
    "kg_extractor = GraphRAGExtractor(\n",
    "    llm=llm,\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=2,\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782a80d-40e5-4854-bb5c-5e9a7a27ded0",
   "metadata": {},
   "source": [
    "# Building the Graph Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1edc8c6-bd50-43f0-bf3a-78fbd21ee8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from llama_index.core.graph_stores import SimplePropertyGraphStore\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "class GraphRAGStore(SimplePropertyGraphStore):\n",
    "    community_summary = {}\n",
    "    max_cluster_size = 5\n",
    "\n",
    "    def generate_community_summary(self, text):\n",
    "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"You are provided with a set of relationships from a knowledge graph, each represented as \"\n",
    "                    \"entity1->entity2->relation->relationship_description. Your task is to create a summary of these \"\n",
    "                    \"relationships. The summary should include the names of the entities involved and a concise synthesis \"\n",
    "                    \"of the relationship descriptions. The goal is to capture the most critical and relevant details that \"\n",
    "                    \"highlight the nature and significance of each relationship. Ensure that the summary is coherent and \"\n",
    "                    \"integrates the information in a way that emphasizes the key aspects of the relationships.\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        response = OpenAI().chat(messages)\n",
    "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return clean_response\n",
    "\n",
    "    def build_communities(self):\n",
    "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
    "        nx_graph = self._create_nx_graph()\n",
    "        community_hierarchical_clusters = hierarchical_leiden(\n",
    "            nx_graph, max_cluster_size=self.max_cluster_size\n",
    "        )\n",
    "        community_info = self._collect_community_info(\n",
    "            nx_graph, community_hierarchical_clusters\n",
    "        )\n",
    "        self._summarize_communities(community_info)\n",
    "\n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        for node in self.graph.nodes.values():\n",
    "            nx_graph.add_node(str(node))\n",
    "        for relation in self.graph.relations.values():\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"relationship_description\"],\n",
    "            )\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(self, nx_graph, clusters):\n",
    "        \"\"\"Collect detailed information for each node based on their community.\"\"\"\n",
    "        community_mapping = {item.node: item.cluster for item in clusters}\n",
    "        community_info = {}\n",
    "        for item in clusters:\n",
    "            cluster_id = item.cluster\n",
    "            node = item.node\n",
    "            if cluster_id not in community_info:\n",
    "                community_info[cluster_id] = []\n",
    "\n",
    "            for neighbor in nx_graph.neighbors(node):\n",
    "                if community_mapping[neighbor] == cluster_id:\n",
    "                    edge_data = nx_graph.get_edge_data(node, neighbor)\n",
    "                    if edge_data:\n",
    "                        detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                        community_info[cluster_id].append(detail)\n",
    "        return community_info\n",
    "\n",
    "    def _summarize_communities(self, community_info):\n",
    "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = (\n",
    "                \"\\n\".join(details) + \".\"\n",
    "            )  # Ensure it ends with a period\n",
    "            self.community_summary[\n",
    "                community_id\n",
    "            ] = self.generate_community_summary(details_text)\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "        return self.community_summary\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes=nodes,\n",
    "    property_graph_store=GraphRAGStore(),\n",
    "    kg_extractors=[kg_extractor],\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c85d2-399d-43c0-8f7a-ad30f86cb940",
   "metadata": {},
   "source": [
    "# Detect Communities and Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f00158aa-10ed-4952-b8a0-390b720a5364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Community ID: 0\n",
      "Summary:\n",
      "I have extracted relationships from a knowledge graph. To create a summary, I will highlight the key entities and their relationships:\n",
      "\n",
      "1. Entity1: Leonardo da Vinci\n",
      "   Entity2: Mona Lisa\n",
      "   Relation: Painted\n",
      "   Relationship Description: Leonardo da Vinci painted the famous portrait of Mona Lisa.\n",
      "\n",
      "2. Entity1: Marie Curie\n",
      "   Entity2: Pierre Curie\n",
      "   Relation: Married to\n",
      "   Relationship Description: Marie Curie was married to Pierre Curie, and together they conducted pioneering research in radioactivity.\n",
      "\n",
      "3. Entity1: Albert Einstein\n",
      "   Entity2: Theory of Relativity\n",
      "   Relation: Developed\n",
      "   Relationship Description: Albert Einstein developed the Theory of Relativity, revolutionizing our understanding of space, time, and gravity.\n",
      "\n",
      "4. Entity1: William Shakespeare\n",
      "   Entity2: Hamlet\n",
      "   Relation: Wrote\n",
      "   Relationship Description: William Shakespeare wrote the tragedy play Hamlet, one of his most famous works exploring themes of revenge and madness.\n",
      "\n",
      "5. Entity1: Steve Jobs\n",
      "   Entity2: Apple Inc.\n",
      "   Relation: Co-founded\n",
      "   Relationship Description: Steve Jobs co-founded Apple Inc., a company that played a significant role in shaping the technology industry with innovative products like the iPhone and Macintosh.\n",
      "\n",
      "These relationships showcase the connections between notable figures and their contributions, whether in the arts, sciences, or business. Each relationship highlights the impact these individuals had on their respective fields, leaving a lasting legacy in history.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 1\n",
      "Summary:\n",
      "Ferdinand Hoyos is a spokesperson for UltraContact NXT, denoted as \"F\" in the relationship. The reciprocal relationship states that UltraContact NXT is represented by Ferdinand Hoyos as a spokesperson, also denoted as \"F\". This indicates a close and mutual association between Ferdinand Hoyos and UltraContact NXT in their spokesperson role, suggesting a strong and significant connection in their communication and representation activities.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 2\n",
      "Summary:\n",
      "Elon Musk, the CEO and developer, is intricately linked to the Tesla Cybertruck. This relationship underscores Musk's pivotal role in the creation and leadership of Tesla, particularly in the development of innovative products like the Cybertruck. The connection highlights Musk's hands-on approach and vision in shaping Tesla's groundbreaking ventures, such as the Cybertruck, which symbolizes the company's commitment to pushing the boundaries of technology and design.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 3\n",
      "Summary:\n",
      "The relationship between \"The Tesla Files\" and the \"Tesla Cybertruck\" is characterized by the revelation of flaws. This suggests that \"The Tesla Files\" have uncovered or highlighted weaknesses or imperfections in the design, functionality, or production of the Tesla Cybertruck. The reciprocal nature of this relationship implies a back-and-forth dynamic where both entities are involved in exposing shortcomings or issues related to the Cybertruck.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 4\n",
      "Summary:\n",
      "Senator Sanders promotes the \"College for All Act\" which signifies his advocacy for accessible higher education. The relationship underscores his commitment to making college education more affordable and inclusive.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 5\n",
      "Summary:\n",
      "Senator Hassan is actively engaged in addressing the issue of affordable housing. She is dedicated to tackling this important issue, demonstrating her commitment to improving access to housing for individuals and families in need.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 6\n",
      "Summary:\n",
      "The relationships in the provided knowledge graph involve Nicky, Caleb Miligan, Gabby Thomas, and the concepts of son-father and forced marriage. Nicky is the son of Caleb Miligan, establishing a familial bond. Additionally, Nicky was involved in a forced marriage with Gabby Thomas, indicating a coercive and likely challenging relationship. These connections highlight complex interpersonal dynamics, including family ties and instances of coercion, underscoring the intricate web of relationships among the individuals involved.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 7\n",
      "Summary:\n",
      "Senator Hassan is actively involved in advocating for the well-being of middle-class families, showing a strong commitment to their interests. Additionally, she is dedicated to protecting houses of worship, highlighting her support for religious freedom and security within these institutions. The relationships underscore Senator Hassan's multifaceted efforts in advocacy and protection, focusing on key societal pillars such as family welfare and religious sanctuaries.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 8\n",
      "Summary:\n",
      "Chris O’Cull, an analyst at a company, is associated with Domino’s Pizza in a significant capacity denoted by the relationship \"C\". This suggests that Chris O’Cull, in his role as an analyst, likely has a professional or business connection with Domino’s Pizza, indicating potential involvement in analyzing or evaluating aspects related to the company. The reciprocal nature of the relationship underscores the mutual interaction and relevance between Chris O’Cull, the company he works for, and Domino’s Pizza.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 9\n",
      "Summary:\n",
      "Stifel and a Recommender-Company have a mutual relationship with Domino’s Pizza, denoted as \"S.\" Stifel is connected to the Recommender-Company through Domino’s Pizza, and vice versa. This reciprocal relationship suggests a significant association between Stifel, the Recommender-Company, and Domino’s Pizza, possibly indicating a partnership, investment, or strategic collaboration among the entities.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 10\n",
      "Summary:\n",
      "Siemens and Roland Busch are connected through an employment relationship. Roland Busch is associated with Siemens in a professional capacity.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 11\n",
      "Summary:\n",
      "Roland Busch and Jin Zhuanglong engaged in a professional meeting denoted by the relationship \"R\".\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 12\n",
      "Summary:\n",
      "Kinsman Oak Capital Partners and Investment Analysis are linked to Lululemon Athletica through a mutual relationship denoted by \"K.\" This suggests that both Kinsman Oak Capital Partners and Investment Analysis have some form of investment or financial interest in Lululemon Athletica. The nature of this connection implies that there is a significant financial involvement or strategic partnership between the entities, likely related to investments, funding, or business collaborations.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 13\n",
      "Summary:\n",
      "Lululemon Athletica and Acquisition and Impairment are interconnected through the Mirror relationship, denoted as L. This suggests a significant link between Lululemon Athletica and the concept of Acquisition and Impairment, possibly indicating a transaction or association between the two entities. The Mirror relationship implies a reflection or mirroring effect, hinting at a close connection or parallelism in the context of Lululemon Athletica and Acquisition and Impairment.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 14\n",
      "Summary:\n",
      "H&M and ASOS are competitors in the fashion industry, with a bidirectional competitive relationship denoted by the \"B\" symbol. H&M attracts investments from various investors, denoted by \"I\", showcasing a significant interest in the company. ASOS also receives investments from investors, indicating a similar level of financial support. This network of relationships highlights the competitive landscape between H&M and ASOS, as well as the financial backing both companies receive from investors.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 15\n",
      "Summary:\n",
      "The relationship between Continental and Manufacturer involves the UltraContact NXT, denoted as \"C.\" This suggests that Continental is associated with a manufacturer in producing or distributing the UltraContact NXT. Similarly, the reverse relationship indicates that the Manufacturer is linked to Continental through the UltraContact NXT.\n",
      "\n",
      "Furthermore, the connection between Manufacturer and Graco Inc. introduces the Electric Variable Ratio Metering System (EVR), represented as \"G.\" This implies that the Manufacturer is involved with Graco Inc. in the development or supply of the Electric Variable Ratio Metering System. The reciprocal relationship highlights that Graco Inc. is also associated with the Manufacturer in the context of the Electric Variable Ratio Metering System (EVR), denoted as \"G.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Community ID: 16\n",
      "Summary:\n",
      "EE and Provider are interconnected entities in a relationship that involves providing a Full Fibre 1.6 Gbps service. This service is significant as it denotes a high-speed internet connection offered by Provider to EE. The reciprocal nature of the relationship, where Provider offers this service to EE and vice versa, highlights a mutual agreement between the two entities to exchange or utilize this high-speed service.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Access the community summaries directly from your GraphRAGStore instance\n",
    "community_summaries = index.property_graph_store.get_community_summaries()\n",
    "\n",
    "# Display the communities nicely\n",
    "for community_id, summary in community_summaries.items():\n",
    "    print(f\"\\nCommunity ID: {community_id}\\nSummary:\\n{summary}\\n{'-'*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80504830-6cab-4cb3-ae01-d06d909d5f0b",
   "metadata": {},
   "source": [
    "# Query the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab5251a5-7d69-4d36-a8a1-cbba82b4d518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided community summary does not contain any information about the relationship between \"The Tesla Files\" and \"Tesla Cybertruck\". Therefore, it's impossible to provide a relationship between them based on the given information. However, it is suggested that \"The Tesla Files\" may have uncovered or highlighted weaknesses or imperfections in the design, functionality, or production of the Tesla Cybertruck, indicating a reciprocal dynamic in their relationship."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.llms import LLM\n",
    "\n",
    "class GraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: GraphRAGStore\n",
    "    llm: LLM\n",
    "\n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
    "        community_summaries = self.graph_store.get_community_summaries()\n",
    "        community_answers = [\n",
    "            self.generate_answer_from_summary(community_summary, query_str)\n",
    "            for _, community_summary in community_summaries.items()\n",
    "        ]\n",
    "\n",
    "        final_answer = self.aggregate_answers(community_answers)\n",
    "        return final_answer\n",
    "\n",
    "    def generate_answer_from_summary(self, community_summary, query):\n",
    "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
    "        prompt = (\n",
    "            f\"Given the community summary: {community_summary}, \"\n",
    "            f\"how would you answer the following query? Query: {query}\"\n",
    "        )\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=\"I need an answer based on the above information.\",\n",
    "            ),\n",
    "        ]\n",
    "        response = self.llm.chat(messages)\n",
    "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return cleaned_response\n",
    "\n",
    "    def aggregate_answers(self, community_answers):\n",
    "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
    "        # intermediate_text = \" \".join(community_answers)\n",
    "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"Intermediate answers: {community_answers}\",\n",
    "            ),\n",
    "        ]\n",
    "        final_response = self.llm.chat(messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response\n",
    "\n",
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store, llm=llm\n",
    ")\n",
    "response = query_engine.query('Show me the relationship between \"The Tesla Files\" and \"Tesla Cybertruck\"')\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec6661-8ffb-4b8e-8b79-8ec92da3b354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7363303-c585-4593-8fec-287dd00cddb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce68533-5b90-4896-ae3f-c4943f826806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781a065-f502-4ffe-9633-895c9ecf6bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
